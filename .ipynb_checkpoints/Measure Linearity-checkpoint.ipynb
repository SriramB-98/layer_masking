{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "553bf427",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './sal_dataset_split.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_862783/522134536.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_image_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accimage'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./sal_dataset_split.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0msalient_imagenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './sal_dataset_split.pkl'"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from dataset_utils import *\n",
    "\n",
    "import pandas as pd \n",
    "from sal_resnet import resnet50\n",
    "from madry_models import vit_base_patch16_224 as vit_b_16\n",
    "\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "seed = 1\n",
    "\n",
    "set_seed(seed)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torchvision.set_image_backend('accimage')\n",
    "\n",
    "salient_dataset = SalientImageNet(IMAGENET_PATH, SALIENT_IMAGENET_PATH, typ='core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e995aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [(resnet50, 'resnet50'), (vit_b_16, 'vit_b_16')]\n",
    "\n",
    "class Identity(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "models = []\n",
    "for model_type, m_name in model_list:\n",
    "    model = model_type(pretrained=True)\n",
    "    if 'resnet' in m_name:\n",
    "        model.fc = Identity()\n",
    "    elif 'vit_b_16' in m_name:\n",
    "        model.head = Identity()\n",
    "    model = MyDataParallel(model).to(device)\n",
    "    models.append(model.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4*torch.cuda.device_count()\n",
    "gpu_size = 64*torch.cuda.device_count()\n",
    "salient_loader = torch.utils.data.DataLoader(salient_imagenet, \n",
    "                                             batch_size=max(gpu_size, 100), \n",
    "                                             shuffle=False, \n",
    "                                             num_workers=num_workers, \n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(imgs, noise):\n",
    "    return (imgs + noise*torch.randn(*imgs.shape, device=device)).clip(0,1)\n",
    "\n",
    "def blackout(imgs):\n",
    "    return torch.zeros_like(imgs, device=device)\n",
    "\n",
    "def greyout(imgs):\n",
    "    return torch.zeros_like(imgs, device=device) + torch.tensor([[[0.485]], [[0.456]], [[0.406]]], device=device)\n",
    "\n",
    "def blur(imgs):\n",
    "    return torchvision.transforms.functional.gaussian_blur(imgs, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blockify(m):\n",
    "    m_new = torch.reshape(m, (-1, 1, 14, 16, 14, 16))\n",
    "    m_sum = m_new.mean(dim=(3,5), keepdims=True)\n",
    "    m_new = torch.broadcast_to(m_sum, m_new.shape) > 0\n",
    "    return m_new.float().reshape(-1, 1, 224, 224)\n",
    "\n",
    "def block_segment(imgs, masks, patch_size=16):\n",
    "    seg_num = 224//patch_size\n",
    "    segments = torch.arange(seg_num*seg_num, dtype=torch.uint8, device=masks.device).reshape(1, 1, seg_num, 1, seg_num, 1)\n",
    "    seg_mask = segments.repeat(1, 1, 1, patch_size, 1, patch_size)\n",
    "    seg_mask = seg_mask.reshape(1, 1, 224, 224).repeat(len(masks), 1, 1, 1)\n",
    "    return seg_mask\n",
    "\n",
    "def bbox_segment(imgs, masks):\n",
    "    inds = torch.argmax(masks.view(masks.shape[0],-1), dim=1)\n",
    "    inds_h = torch.div(inds, 224, rounding_mode='floor')\n",
    "    inds_v = inds - inds_h*224\n",
    "    seg_masks = torch.zeros_like(masks, dtype=torch.uint8)\n",
    "    tl = list(range(150, 0, -10))\n",
    "#     print(tl)\n",
    "#     print(inds_h, inds_v)\n",
    "    for i, (ih, iv) in enumerate(zip(inds_h, inds_v)):\n",
    "        ih, iv = ih.item(), iv.item()\n",
    "        for it, t in enumerate(tl):\n",
    "            seg_masks[i][0][max(0, ih-t):min(ih+t, 224), max(0, iv-t):min(iv+t, 224)] = it+1\n",
    "    return seg_masks\n",
    "\n",
    "def contour_segment(imgs, masks):\n",
    "    tl = np.array(range(0, 20))/20\n",
    "    seg_masks = torch.zeros_like(masks, dtype=torch.uint8)\n",
    "    for i, t in enumerate(tl):\n",
    "        seg_masks[(masks > t)] = (i+1)\n",
    "    return seg_masks\n",
    "\n",
    "# def sklearn_segment(imgs, masks, skseg_fn=quickshift):\n",
    "#     seg_masks = []\n",
    "#     for i, img in enumerate(imgs):\n",
    "#         img = img.permute(1,2,0).numpy()\n",
    "#         sm = torch.Tensor(skseg_fn(img), device=masks.device).to(torch.uint8)\n",
    "#         seg_masks.append(sm[None,:])\n",
    "#     seg_masks = torch.stack(seg_masks, dim=0)\n",
    "#     return seg_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be020b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_dist(bp, bvset):\n",
    "    '''\n",
    "    bp.shape: (bsize, fdim)\n",
    "    bvset.shape: (bsize, n, fdim)\n",
    "    '''\n",
    "#     bvset_mask = bvset.max(dim=-1).values == 0\n",
    "#     bvset[bvset_mask] += 1e-6\n",
    "    bvset = bvset + bvset.mean(dim=1, keepdims=True)\n",
    "    sol = torch.linalg.lstsq(bvset.permute(0,2,1), bp[:,:,None]).solution\n",
    "    return torch.linalg.norm(torch.einsum('ijk,ijl->il', sol, bvset) - bp, dim=-1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "sal_degrees = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,  1.0]\n",
    "corruptions = [\n",
    "               blackout,\n",
    "               greyout,\n",
    "#                blur,\n",
    "               None\n",
    "              ]\n",
    "corr_names = [\n",
    "              \"Blackout\",\n",
    "              \"Greyout\",\n",
    "#               \"Blur\",\n",
    "              'Layer masking',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45257af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_patch(bs, num_patches, n, seg_masks):\n",
    "    n = num_patches\n",
    "    inds = [torch.randperm(num_patches)[:n].to(seg_masks.device) for i in range(bs)]\n",
    "    masks = torch.ones(bs, n, 224, 224, device=seg_masks.device)\n",
    "    for i, ind in enumerate(inds):\n",
    "        masks[i, :, :, :] = (seg_masks[i] == ind.view(-1, 1, 1)).float()\n",
    "    masks = masks.permute(1,0,2,3)\n",
    "    masks = masks[:,:,None]\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b9f7e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "patch_sizes = [32, 16]\n",
    "all_dists = np.zeros((len(corruptions), len(patch_sizes), len(models)))\n",
    "all_cos_sims = np.zeros((len(corruptions), len(patch_sizes), len(models)))\n",
    "all_feature_vector_mags = np.zeros((len(corruptions), len(patch_sizes), len(models)))\n",
    "baseline_dist = 0\n",
    "seg_fn = block_segment\n",
    "num_patches = 4\n",
    "total = 0\n",
    "eps = 1e-8\n",
    "ad = []\n",
    "bd = []\n",
    "for i, (imgs, sal_masks, labels) in enumerate(salient_loader):\n",
    "    print(i)\n",
    "    for pi, ps in enumerate(patch_sizes):\n",
    "        seg_mask = seg_fn(imgs, sal_masks, patch_size=ps).to(device)\n",
    "        num_segs = seg_mask.max().item()+1\n",
    "        print(pi, ps, num_segs)\n",
    "        with torch.no_grad():\n",
    "\n",
    "            corr_imgs = []\n",
    "            for ci, corr in enumerate(corruptions):\n",
    "                if corr is not None:\n",
    "                    corr_imgs.append(corr(imgs))\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            masks = get_random_patch(len(imgs), num_segs, num_patches, seg_mask)\n",
    "\n",
    "            all_mask = (masks).sum(dim=0)\n",
    "\n",
    "            for ci, corr in enumerate(corruptions):\n",
    "                for mi, model in enumerate(models):\n",
    "                    if corr is None:\n",
    "                        features_list = [model((normalizer(imgs), m, [100, 5])).cpu() for m in masks]\n",
    "                        combined_features = model((normalizer(imgs), all_mask, [100,5])).cpu()\n",
    "                    else:\n",
    "                        features_list = [model(normalizer(corr_imgs[ci].to(device)*(1-m) + imgs*(m))).cpu() for m in masks]\n",
    "                        combined_features = model(normalizer(corr_imgs[ci].to(device)*(1-all_mask) + imgs*(all_mask))).cpu()\n",
    "                    basis_features = torch.stack(features_list, dim=1)\n",
    "#                     basis_features = torch.linalg.norm(basis_features, dim=-1, keepdim=True)\n",
    "#                     combined_features = torch.linalg.norm(combined_features, dim=-1, keepdim=True)\n",
    "\n",
    "        #             basis_features = basis_features/(1e-5 + torch.linalg.norm(basis_features, dim=-1, keepdims=True))\n",
    "        #             combined_features = combined_features/(1e-5 + torch.linalg.norm(combined_features, dim=-1, keepdims=True))\n",
    "        #             dists = project_dist(combined_features, basis_features)\n",
    "#                     basis_features = torch.stack(features_list, dim=1)\n",
    "                    cos_sims = cosine_similarity(torch.sum(basis_features, dim=1), combined_features)\n",
    "                    dists = torch.linalg.norm(torch.sum(basis_features, dim=1) - combined_features, dim=-1)/(eps + torch.linalg.norm(combined_features, dim=-1))\n",
    "                    feature_vector_mags = torch.linalg.norm(basis_features, dim=-1).mean(1)\n",
    "                    \n",
    "                    all_dists[ci][pi][mi] += (dists).sum()\n",
    "                    all_cos_sims[ci][pi][mi] += (cos_sims).sum()\n",
    "                    all_feature_vector_mags[ci][pi][mi] += (feature_vector_mags).sum()\n",
    "            \n",
    "    total += len(imgs)    \n",
    "    print(np.round(all_dists, 3).transpose()/total)\n",
    "    print(np.round(all_cos_sims, 3).transpose()/total)\n",
    "    print(np.round(all_feature_vector_mags, 3).transpose()/total)\n",
    "    \n",
    "    if total > 1_000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f0243",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/linearity_all_dists.npy', all_dists/total)\n",
    "np.save('./results/linearity_all_cos_sims.npy', all_cos_sims/total)\n",
    "np.save('./results/linearity_all_feature_vector_mags.npy', all_feature_vector_mags/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcdc432",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    pd.DataFrame(np.round(all_dists, 3).transpose()[i], index=[f'{ps} X {ps}' for ps in patch_sizes]).to_latex(open(f\"./results/linearity_{model_list[i][1]}.csv\", 'a'),\n",
    "                                                          header=corr_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
