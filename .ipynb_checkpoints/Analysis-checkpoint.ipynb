{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "553bf427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from dataset_utils import *\n",
    "import timm\n",
    "from sal_resnet import resnet50, resnext50_32x4d, wide_resnet50_2\n",
    "from alexnet import alexnet\n",
    "from efficientnet import efficientnet_b0\n",
    "from squeezenet import squeezenet1_1\n",
    "from madry_models import vit_base_patch16_224 as vit_b_16, deit_base_patch16_224 as deit_b_16\n",
    "\n",
    "from mobilenet import mobilenet_v2, mobilenet_v3_large\n",
    "from densenet import densenet121\n",
    "from collections import defaultdict\n",
    "\n",
    "from skimage.segmentation import quickshift, slic\n",
    "\n",
    "seed = 1\n",
    "\n",
    "set_seed(seed)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torchvision.set_image_backend('accimage')\n",
    "\n",
    "### Update Imagenet path and Salient Imagenet path\n",
    "\n",
    "## If using Salient ImageNet, make sure that the filepaths used in the SalientImageNet class is correct, \n",
    "### since there is no standard path for this dataset. All information and files can be found in the github link:\n",
    "### https://github.com/singlasahil14/salient_imagenet\n",
    "\n",
    "salient_dataset = SalientImageNet(IMAGENET_PATH, SALIENT_IMAGENET_PATH, typ='core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1fd53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4*torch.cuda.device_count()\n",
    "gpu_size = 128*torch.cuda.device_count()\n",
    "salient_loader = torch.utils.data.DataLoader(salient_dataset, \n",
    "                                             batch_size=max(gpu_size, 100), \n",
    "                                             shuffle=False, \n",
    "                                             num_workers=num_workers, \n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c34c38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(imgs, noise):\n",
    "    return (imgs + noise*torch.randn(*imgs.shape, device=device)).clip(0,1)\n",
    "\n",
    "def blackout(imgs):\n",
    "    return torch.zeros_like(imgs, device=device)\n",
    "\n",
    "def greyout(imgs):\n",
    "    return torch.zeros_like(imgs, device=device) + torch.tensor([[[0.485]], [[0.456]], [[0.406]]], device=device)\n",
    "\n",
    "def averageout(imgs):\n",
    "    return torch.mean(imgs, dim=(2,3), keepdim=True)\n",
    "\n",
    "def redout(imgs):\n",
    "    return torch.zeros_like(imgs, device=device) + torch.tensor([[[1.]], [[0.]], [[0.]]], device=device)\n",
    "\n",
    "def blueout(imgs):\n",
    "    return torch.zeros_like(imgs, device=device) + torch.tensor([[[0.]], [[0.]], [[1.]]], device=device)\n",
    "\n",
    "def greenout(imgs):\n",
    "    return torch.zeros_like(imgs, device=device) + torch.tensor([[[0.]], [[1.]], [[0.]]], device=device)\n",
    "\n",
    "def blur(imgs):\n",
    "    return torchvision.transforms.functional.gaussian_blur((imgs), 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f409ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blockify(m):\n",
    "    m_new = torch.reshape(m, (-1, 1, 14, 16, 14, 16))\n",
    "    m_sum = m_new.mean(dim=(3,5), keepdims=True)\n",
    "    m_new = torch.broadcast_to(m_sum, m_new.shape) > 0\n",
    "    return m_new.float().reshape(-1, 1, 224, 224)\n",
    "\n",
    "def block_segment(imgs, masks, patch_size=16):\n",
    "    num_patch = 224//patch_size\n",
    "    segments = torch.arange(num_patch*num_patch, \n",
    "                            dtype=torch.uint8, device=masks.device).reshape(1, 1, num_patch, 1, num_patch, 1)\n",
    "    seg_mask = segments.repeat(1, 1, 1, patch_size, 1, patch_size)\n",
    "    seg_mask = seg_mask.reshape(1, 1, 224, 224).repeat(len(masks), 1, 1, 1)\n",
    "    return seg_mask\n",
    "\n",
    "def bbox_segment(imgs, masks):\n",
    "    inds = torch.argmax(masks.view(masks.shape[0],-1), dim=1)\n",
    "    inds_h = torch.div(inds, 224, rounding_mode='floor')\n",
    "    inds_v = inds - inds_h*224\n",
    "    seg_masks = torch.zeros_like(masks, dtype=torch.uint8)\n",
    "    tl = list(range(150, 0, -10))\n",
    "#     print(tl)\n",
    "#     print(inds_h, inds_v)\n",
    "    for i, (ih, iv) in enumerate(zip(inds_h, inds_v)):\n",
    "        ih, iv = ih.item(), iv.item()\n",
    "        for it, t in enumerate(tl):\n",
    "            seg_masks[i][0][max(0, ih-t):min(ih+t, 224), max(0, iv-t):min(iv+t, 224)] = it+1\n",
    "    return seg_masks\n",
    "\n",
    "def contour_segment(imgs, masks):\n",
    "    tl = np.array(range(0, 20))/20\n",
    "    seg_masks = torch.zeros_like(masks, dtype=torch.uint8)\n",
    "    for i, t in enumerate(tl):\n",
    "        seg_masks[(masks > t)] = (i+1)\n",
    "    return seg_masks\n",
    "\n",
    "def sklearn_segment(imgs, masks, skseg_fn=quickshift):\n",
    "    seg_masks = []\n",
    "    imgs = imgs.cpu()\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.permute(1,2,0).numpy()\n",
    "        sm = torch.Tensor(skseg_fn(img), device=masks.device)#.to(torch.uint8)\n",
    "        seg_masks.append(sm[None,:])\n",
    "    seg_masks = torch.stack(seg_masks, dim=0)\n",
    "    return seg_masks\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a7c0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seg_order(sal_mask, seg_mask, eps=1e-6):\n",
    "    num_segs = int(seg_mask.max().item()+1)\n",
    "    seg_sal_vals = []\n",
    "    for i in range(num_segs):\n",
    "        seg_sal_vals.append(torch.sum(sal_mask*(seg_mask == i), dim=(1,2,3)))#/(torch.sum((seg_mask == i), dim=(1,2,3))+eps))\n",
    "    seg_sal_vals = torch.stack(seg_sal_vals, dim=-1)\n",
    "    seg_order = torch.argsort(seg_sal_vals, dim=-1, descending=False)\n",
    "    return seg_order#.to(torch.uint8)\n",
    "\n",
    "def mask_seg_inds(seg_inds, seg_mask):\n",
    "    return (torch.sum((seg_inds[:,:,None,None,None] == seg_mask[:,  None, :, :, :]), dim=1) > 0).float()\n",
    "\n",
    "def plot_metric(sal_degrees, accuracies, corr_names, save_path=None):\n",
    "    for i in range(len(accuracies)):\n",
    "        plt.plot(sal_degrees, accuracies[i], label=corr_names[i])\n",
    "    plt.legend()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        plt.clf()\n",
    "    else:\n",
    "        plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ec8e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_degrees = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,  1.0]\n",
    "corruptions = [\n",
    "               (blackout, \"Blackout\"),\n",
    "               (greyout, \"Greyout\"),\n",
    "               ([1000, 1000],\"Layer mask\"),\n",
    "#                 (averageout, 'Average'),\n",
    "#                 (redout, \"Red\"),\n",
    "#                 (blueout, \"Blue\"),\n",
    "#                 (greenout, \"Green\")        \n",
    "#                 ([7, 0,],\"First convolution layer\"),\n",
    "#                 ([7, 2,],\"First two resnet blocks\"),\n",
    "#                 ([0, 4,],\"No padding\"),\n",
    "              ]\n",
    "mtypes = [\n",
    "          (wide_resnet50_2, 'wide_resnet50'),\n",
    "          (resnet50, 'resnet50'), \n",
    "          (deit_b_16, 'DeiT-B-16'),\n",
    "            (squeezenet1_1, 'SqueezeNet'),\n",
    "            (alexnet, 'AlexNet'),\n",
    "            (densenet121, 'DenseNet'),\n",
    "            (efficientnet_b0, 'EfficientNet'),\n",
    "            (mobilenet_v3_large, 'MobileNet'),\n",
    "        ]\n",
    "seg_fns = [\n",
    "            (lambda x, y: sklearn_segment(x, y, \n",
    "                              skseg_fn=lambda x: quickshift(x,kernel_size=4,\n",
    "                                                            max_dist=200, ratio=0.2,\n",
    "                                                            random_seed=0)),  'quickshift'),\n",
    "            (lambda x, y: block_segment(x, y, patch_size=16), '16x16'),\n",
    "#             (contour_segment, 'contour'),\n",
    "            (lambda x, y: sklearn_segment(x, y, skseg_fn=slic), 'slic'),\n",
    "            ]\n",
    "orders = [\n",
    "            'random', \n",
    "            'start_from_sal', \n",
    "            'start_from_nsal'\n",
    "        ] \n",
    "skip_inds = []# [(si, oi, ci, 1) for si in range(len(seg_fns)) for oi in range(len(orders)) for ci in [3, 4, 5] ]\n",
    "write = True\n",
    "desc = \"\"\n",
    "num_samples = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4913898",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_sims = np.load('./wn_sims.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f1e992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>[Loaded PyTorch-pretrained deit checkpoint.]\n",
      "0\n",
      "quickshift 88\n",
      "random\n",
      "start_from_sal\n",
      "start_from_nsal\n",
      "16x16 196\n",
      "random\n",
      "start_from_sal\n",
      "start_from_nsal\n",
      "slic 98\n",
      "random\n",
      "start_from_sal\n",
      "start_from_nsal\n",
      "Writing..\n",
      "1\n",
      "quickshift 137\n",
      "random\n",
      "start_from_sal\n",
      "start_from_nsal\n",
      "16x16 196\n",
      "random\n",
      "start_from_sal\n"
     ]
    }
   ],
   "source": [
    "models = [(MyDataParallel(mtype(pretrained=True)).to(device).eval(), m_name) for mtype, m_name in mtypes]\n",
    "normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "models.append((timm.create_model('resnet50', pretrained=True).to(device).eval(), 'resnet50_timm'))\n",
    "\n",
    "# seg_fn = lambda x, y: sklearn_segment(x, y, skseg_fn=quickshift)\n",
    "res_shape = (len(seg_fns), len(orders), len(corruptions), len(models), len(sal_degrees))\n",
    "total_hits = np.zeros(res_shape)\n",
    "class_counts = np.zeros((*res_shape, 1000))\n",
    "wn_sim_hits = np.zeros(res_shape)\n",
    "unchanged_preds = np.zeros(res_shape)\n",
    "total = 0\n",
    "for i, (imgs, masks, labels) in enumerate(salient_loader):\n",
    "    print(i)\n",
    "    \n",
    "    corr_imgs = []\n",
    "    for ci, (corr, corr_name) in enumerate(corruptions):\n",
    "        if not isinstance(corr, list):\n",
    "            corr_imgs.append(corr(imgs))\n",
    "    \n",
    "    for si, (seg_fn, seg_fn_name) in enumerate(seg_fns):\n",
    "        seg_mask = seg_fn(imgs, masks)\n",
    "        num_segs = int(seg_mask.max().item()+1)\n",
    "        print(seg_fn_name,num_segs)\n",
    "        if num_segs > 200:\n",
    "            print(seg_fn_name, \" skipped\")\n",
    "            continue\n",
    "        for oi, order in enumerate(orders):\n",
    "            print(order)\n",
    "            if order == 'start_from_sal' or order == 'start_from_nsal':\n",
    "                seg_order = extract_seg_order(masks, seg_mask)\n",
    "            elif order == 'random':\n",
    "                rand_order = torch.argsort(torch.rand(len(masks), num_segs), dim=-1, descending=False)\n",
    "\n",
    "            corr_masks = []\n",
    "            for di, d in enumerate(sal_degrees):\n",
    "                if order == 'start_from_sal':\n",
    "                    m = mask_seg_inds(seg_order[:,num_segs-int(d*num_segs):], seg_mask)\n",
    "                elif order == 'start_from_nsal':\n",
    "                    m = mask_seg_inds(seg_order[:, :int(d*num_segs)], seg_mask)\n",
    "                elif order == 'random': \n",
    "                    m = mask_seg_inds(rand_order[:, :int(d*num_segs)], seg_mask)\n",
    "                corr_masks.append(m)\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "#             raise Exception()\n",
    "            for ci, (corr, corr_name) in enumerate(corruptions):\n",
    "                for mi, (model, mname) in enumerate(models):\n",
    "                    if (si, oi, ci, mi) in skip_inds:\n",
    "                        continue\n",
    "                    for di, d in enumerate(sal_degrees):\n",
    "                        m = corr_masks[di].to(device)                   \n",
    "                        with torch.no_grad():\n",
    "                            if isinstance(corr, list):\n",
    "                                logits = model((normalizer(imgs)*(1-m), 1-m, corr))\n",
    "                            else:\n",
    "                                probe_imgs = corr_imgs[ci].to(device)*m + imgs*(1-m)\n",
    "                                logits = model(normalizer(probe_imgs))  \n",
    "                        preds = logits.argmax(-1)\n",
    "                        if d == 0:\n",
    "                            init_preds = preds\n",
    "                        total_hits[si][oi][ci][mi][di] += (preds == labels).float().sum().item()\n",
    "                        class_counts[si][oi][ci][mi][di] +=  torch.bincount(preds, minlength=1000).cpu().numpy()\n",
    "                        unchanged_preds[si][oi][ci][mi][di] += (preds == init_preds).float().sum().item()\n",
    "                        wn_sim_hits[si][oi][ci][mi][di] += np.sum([wn_sims[p.item()][l.item()] for p, l in zip(preds, labels) ])\n",
    "        \n",
    "    total += len(imgs)\n",
    "    \n",
    "    ntotal_hits = total_hits/total\n",
    "    nclass_counts = class_counts/total\n",
    "    nwn_sim_hits = wn_sim_hits/total\n",
    "    nunchanged_preds = unchanged_preds/total\n",
    "#     raise Exception()\n",
    "    if write:\n",
    "        print('Writing..')\n",
    "        np.save(f'./results/total_hits_{desc}.npy', total_hits)\n",
    "        np.save(f'./results/class_counts_{desc}.npy', class_counts)\n",
    "        np.save(f'./results/wn_sim_hits_{desc}.npy', wn_sim_hits)\n",
    "        np.save(f'./results/unchanged_preds_{desc}.npy', unchanged_preds)\n",
    "    if total > num_samples:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
