{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f42e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from utils import *\n",
    "from dataset_utils import *\n",
    "from sal_resnet import resnet50\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from alexnet import alexnet\n",
    "from squeezenet import squeezenet1_1\n",
    "from densenet import densenet121\n",
    "\n",
    "seed = 1\n",
    "from sal_resnet import resnet50, resnext50_32x4d, wide_resnet50_2\n",
    "from madry_models import vit_base_patch16_224 as vit_b_16, deit_base_patch16_224 as deit_b_16\n",
    "\n",
    "set_seed(seed)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "# torchvision.set_image_backend('accimage')\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1894822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "                    transforms.Resize(224, interpolation=BICUBIC, max_size=None, antialias=None),\n",
    "                    transforms.CenterCrop(size=(224, 224)),\n",
    "                    transforms.ToTensor()\n",
    "                    ])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "                    transforms.Resize(224, interpolation=NEAREST, max_size=None, antialias=None),\n",
    "                    transforms.CenterCrop(size=(224, 224)),\n",
    "                    ToTensor()\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa54ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_imagenet = PixelImageNet(IMAGENET_PATH, \n",
    "                             PIXEL_IMAGENET_PATH,\n",
    "                             img_transform=img_transform, mask_transform=mask_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea46bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4*torch.cuda.device_count()\n",
    "gpu_size = 256*torch.cuda.device_count()\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "pixel_imagenet_loader = torch.utils.data.DataLoader(pixel_imagenet, \n",
    "                                                     batch_size=max(gpu_size, 100), \n",
    "                                                     num_workers=num_workers, \n",
    "                                                     pin_memory=True,\n",
    "                                                     shuffle=False,\n",
    "#                                                      sampler=SubsetRandomSampler(indices=),\n",
    "                                                     drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9abeaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackout(imgs):\n",
    "    return torch.zeros_like(imgs, device=imgs.device)\n",
    "\n",
    "def greyout(imgs):\n",
    "    return torch.zeros_like(imgs, device=imgs.device) + torch.tensor([[[0.485]], [[0.456]], [[0.406]]], device=imgs.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d46b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet import efficientnet_b0\n",
    "from squeezenet import squeezenet1_1\n",
    "from mobilenet import mobilenet_v2, mobilenet_v3_large\n",
    "from densenet import densenet121\n",
    "model_list = [\n",
    "              (resnet50, 'resnet50'), \n",
    "#               (deit_b_16, 'deit_b_16'),\n",
    "              (wide_resnet50_2, 'wide_resnet50'),\n",
    "              (alexnet, 'AlexNet'),\n",
    "              (efficientnet_b0, 'EfficientNet'),\n",
    "              (mobilenet_v3_large, 'MobileNet'),\n",
    "              (squeezenet1_1, 'SqueezeNet'),\n",
    "              (densenet121, 'DenseNet'),\n",
    "             ]\n",
    "models = [(MyDataParallel(model_type(pretrained=True)).to(device).eval(), model_name) for model_type, model_name in model_list]\n",
    "models.append((MyDataParallel(timm.create_model('resnet50', pretrained=True)).to(device).eval(), 'ResNet50_timm'))\n",
    "baselines = [(blackout, \"Blackout\"),\n",
    "            (greyout, \"Greyout\"),\n",
    "            ([1000, 1000],\"Layer mask\")]\n",
    "normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2bb9b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 resnet50 0.23318385650224216 0.21748878923766815 0.16442451420029897 0.6831091180866966 0.7227204783258595 0.8101644245142003\n",
      "5 wide_resnet50 0.23727647867950483 0.23727647867950483 0.19119669876203577 0.7455295735900963 0.7861072902338377 0.8431911966987621\n",
      "5 AlexNet 0.18886861313868614 0.16697080291970803 0.1478102189781022 0.4625912408759124 0.5611313868613139 0.6751824817518248\n",
      "5 EfficientNet 0.25734767025089605 0.207168458781362 0.16774193548387098 0.7677419354838709 0.8767025089605734 0.7849462365591398\n",
      "5 MobileNet 0.24517512508934952 0.24088634739099357 0.1658327376697641 0.7169406719085061 0.8227305218012866 0.725518227305218\n",
      "5 SqueezeNet 0.1395112016293279 0.1364562118126273 0.11812627291242363 0.48879837067209775 0.560081466395112 0.659877800407332\n",
      "5 DenseNet 0.20061967467079783 0.203718048024787 0.13632842757552285 0.7025561580170411 0.7257939581719597 0.7567776917118513\n",
      "5 ResNet50_timm 0.29859154929577464 0.28732394366197184 0.22605633802816902 0.8492957746478873 0.9091549295774648 0.8598591549295774\n",
      "10 resnet50 0.23645320197044334 0.22249589490968802 0.16912972085385877 0.6954022988505747 0.7249589490968801 0.8181444991789819\n",
      "10 wide_resnet50 0.24122479462285287 0.2419716206123973 0.1960418222554145 0.739731142643764 0.7823002240477969 0.8405526512322629\n",
      "10 AlexNet 0.189817103311913 0.1814137419673752 0.16411270390509144 0.46910528917449335 0.5605536332179931 0.6866040533860603\n",
      "10 EfficientNet 0.2688679245283019 0.22327044025157233 0.17767295597484276 0.7720125786163522 0.8805031446540881 0.7877358490566038\n",
      "10 MobileNet 0.2540983606557377 0.25136612021857924 0.16588602654176424 0.7189695550351288 0.8321623731459797 0.7283372365339579\n",
      "10 SqueezeNet 0.15134837644468904 0.14254265272427077 0.12878370941111722 0.5063291139240507 0.5663181067694001 0.6642817831590534\n",
      "10 DenseNet 0.21159542953872196 0.2204824375793483 0.1472704189589505 0.7151925518408803 0.735928903935675 0.7608971646212441\n",
      "10 ResNet50_timm 0.30855161787365176 0.3008474576271186 0.24075500770416025 0.8543913713405239 0.9148690292758089 0.8613251155624037\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model(normalizer(imgs\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mmasks) \u001b[38;5;241m+\u001b[39m b(imgs)\u001b[38;5;241m*\u001b[39mmasks))\n\u001b[0;32m---> 24\u001b[0m     sq_logits \u001b[38;5;241m=\u001b[39m model(normalizer(\u001b[43mimgs\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43msq_masks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msq_masks\u001b[49m))\n\u001b[1;32m     25\u001b[0m all_masked_preds[model_name][bname] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(logits\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     26\u001b[0m all_sqmasked_preds[model_name][bname] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(sq_logits\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_clean_preds = defaultdict(list)\n",
    "all_masked_preds = dict([(model_name, defaultdict(list)) for _, model_name in models])\n",
    "all_sqmasked_preds = dict([(model_name, defaultdict(list)) for _, model_name in models])\n",
    "\n",
    "all_labels = []\n",
    "hi, wi = torch.arange(224), torch.arange(224)\n",
    "for i, (imgs, masks, labels) in enumerate(pixel_imagenet_loader):\n",
    "    all_labels += list(labels.numpy())\n",
    "    \n",
    "    sq_masks = torch.cat((masks[:,:,112:], masks[:,:,:112]), dim=2)\n",
    "    sq_masks = torch.cat((sq_masks[:,:,:,112:], sq_masks[:,:,:,:112]), dim=3)\n",
    "    \n",
    "    for model, model_name in models:\n",
    "        with torch.no_grad():\n",
    "            clean_logits = model(normalizer(imgs))\n",
    "            clean_preds = list(clean_logits.argmax(-1).cpu().numpy())\n",
    "            all_clean_preds[model_name] += clean_preds\n",
    "            for b, bname in baselines:\n",
    "                if isinstance(b, list):\n",
    "                    logits = model((normalizer(imgs)*(1-masks), 1-masks, b))\n",
    "                    sq_logits = model((normalizer(imgs)*(1-sq_masks), 1-sq_masks, b))\n",
    "                else:\n",
    "                    logits = model(normalizer(imgs*(1-masks) + b(imgs)*masks))\n",
    "                    sq_logits = model(normalizer(imgs*(1-sq_masks) + b(imgs)*sq_masks))\n",
    "                all_masked_preds[model_name][bname] += list(logits.argmax(-1).cpu().numpy())\n",
    "                all_sqmasked_preds[model_name][bname] += list(sq_logits.argmax(-1).cpu().numpy())\n",
    "        if i % 5 == 0 and i != 0:\n",
    "            hits = (np.array(all_labels) == np.array(all_clean_preds[model_name]))\n",
    "            blackout_hits = (np.array(all_masked_preds[model_name]['Blackout']) == np.array(all_labels))\n",
    "            greyout_hits = (np.array(all_masked_preds[model_name]['Greyout']) == np.array(all_labels))\n",
    "            lm_hits = (np.array(all_masked_preds[model_name]['Layer mask']) == np.array(all_labels))\n",
    "            sq_blackout_hits = (np.array(all_sqmasked_preds[model_name]['Blackout']) == np.array(all_labels))\n",
    "            sq_greyout_hits = (np.array(all_sqmasked_preds[model_name]['Greyout']) == np.array(all_labels))\n",
    "            sq_lm_hits = (np.array(all_sqmasked_preds[model_name]['Layer mask']) == np.array(all_labels))\n",
    "            print(i, model_name, blackout_hits[hits].mean(), greyout_hits[hits].mean(), lm_hits[hits].mean(),\n",
    "                  sq_blackout_hits[hits].mean(), sq_greyout_hits[hits].mean(), sq_lm_hits[hits].mean())\n",
    "        \n",
    "desc = 'more_models'\n",
    "with open(f'./results/pixel_imgnet_clean_preds_{desc}.pkl','wb+') as fp:\n",
    "    pickle.dump(all_clean_preds, fp)\n",
    "with open(f'./results/pixel_imgnet_masked_preds_{desc}.pkl','wb+') as fp:\n",
    "    pickle.dump(all_masked_preds, fp)\n",
    "with open(f'./results/pixel_imgnet_labels_{desc}.pkl','wb+') as fp:\n",
    "    pickle.dump(all_labels, fp)\n",
    "with open(f'./results/pixel_imgnet_broken_masked_preds_{desc}.pkl','wb+') as fp:\n",
    "    pickle.dump(all_sqmasked_preds, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
